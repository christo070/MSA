{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 -q install h5py validators tqdm numpy argparse requests colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/CMU-MultiComp-Lab/CMU-MultimodalSDK.git\n",
    "!cp -r CMU-MultimodalSDK/mmsdk ./\n",
    "!rm -rf CMU-MultimodalSDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m[2024-01-20 06:01:21.704] | Error   | \u001b[0m./cmu_mosi/CMU_MOSI_TimestampedWordVectors.csd file already exists ...\n",
      "High-level features have been downloaded previously.\n",
      "\u001b[91m\u001b[1m[2024-01-20 06:01:21.705] | Error   | \u001b[0m./cmu_mosi/CMU_MOSI_TimestampedWords.csd file already exists ...\n",
      "Raw data have been downloaded previously.\n",
      "\u001b[91m\u001b[1m[2024-01-20 06:01:21.705] | Error   | \u001b[0m./cmu_mosi/CMU_MOSI_Opinion_Labels.csd file already exists ...\n",
      "Labels have been downloaded previously.\n"
     ]
    }
   ],
   "source": [
    "import mmsdk\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from mmsdk import mmdatasdk as md\n",
    "from subprocess import check_call, CalledProcessError\n",
    "\n",
    "DATA_PATH = './cmu_mosi/'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "    \n",
    "# download highlevel features, low-level (raw) data and labels for the dataset MOSI\n",
    "# if the files are already present, instead of downloading it you just load it yourself.\n",
    "# here we use CMU_MOSI dataset as example.\n",
    "\n",
    "DATASET = md.cmu_mosi\n",
    "# obtain the train/dev/test splits - these splits are based on video IDs\n",
    "train_split = DATASET.standard_folds.standard_train_fold\n",
    "dev_split = DATASET.standard_folds.standard_valid_fold\n",
    "test_split = DATASET.standard_folds.standard_test_fold\n",
    "\n",
    "try:\n",
    "    md.mmdataset(DATASET.highlevel, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"High-level features have been downloaded previously.\")\n",
    "\n",
    "try:\n",
    "    md.mmdataset(DATASET.raw, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"Raw data have been downloaded previously.\")\n",
    "    \n",
    "try:\n",
    "    md.mmdataset(DATASET.labels, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"Labels have been downloaded previously.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU_MOSI_TimestampedWordVectors.csd\n",
      "CMU_MOSI_Visual_Facet_42.csd\n",
      "CMU_MOSI_Opinion_Labels.csd\n",
      "CMU_MOSI_TimestampedWords.csd\n",
      "CMU_MOSI_TimestampedPhones.csd\n",
      "CMU_MOSI_openSMILE_IS09.csd\n",
      "CMU_MOSI_OpenSmile_EB10.csd\n",
      "CMU_MOSI_Visual_Facet_41.csd\n"
     ]
    }
   ],
   "source": [
    "data_files = os.listdir(DATA_PATH)\n",
    "print('\\n'.join(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:01:27.656] | Success | \u001b[0mComputational sequence read from file ./cmu_mosi/CMU_MOSI_TimestampedWords.csd ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.662] | Status  | \u001b[0mChecking the integrity of the <words> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.662] | Status  | \u001b[0mChecking the format of the data in <words> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:01:27.693] | Success | \u001b[0m<words> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.693] | Status  | \u001b[0mChecking the format of the metadata in <words> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:01:27.693] | Warning | \u001b[0m<words> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:01:27.693] | Success | \u001b[0mComputational sequence read from file ./cmu_mosi/CMU_MOSI_Visual_Facet_42.csd ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.698] | Status  | \u001b[0mChecking the integrity of the <FACET_4.2> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.698] | Status  | \u001b[0mChecking the format of the data in <FACET_4.2> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:01:27.727] | Success | \u001b[0m<FACET_4.2> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.727] | Status  | \u001b[0mChecking the format of the metadata in <FACET_4.2> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:01:27.727] | Warning | \u001b[0m<FACET_4.2> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:01:27.728] | Success | \u001b[0mComputational sequence read from file ./cmu_mosi/CMU_MOSI_OpenSmile_EB10.csd ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.731] | Status  | \u001b[0mChecking the integrity of the <OpenSmile_emobase2010> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.731] | Status  | \u001b[0mChecking the format of the data in <OpenSmile_emobase2010> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:01:27.777] | Success | \u001b[0m<OpenSmile_emobase2010> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:01:27.777] | Status  | \u001b[0mChecking the format of the metadata in <OpenSmile_emobase2010> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:01:27.777] | Warning | \u001b[0m<OpenSmile_emobase2010> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:01:27.777] | Success | \u001b[0mDataset initialized successfully ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# define your different modalities - refer to the filenames of the CSD files\n",
    "visual_field = 'CMU_MOSI_Visual_Facet_42'\n",
    "acoustic_field = 'CMU_MOSI_OpenSmile_EB10'\n",
    "text_field = 'CMU_MOSI_TimestampedWords'\n",
    "label_field = 'CMU_MOSI_Opinion_Labels'\n",
    "\n",
    "features = [\n",
    "    text_field, \n",
    "    visual_field, \n",
    "    acoustic_field,\n",
    "]\n",
    "\n",
    "recipe = {feat: os.path.join(DATA_PATH, feat) + '.csd' for feat in features}\n",
    "dataset = md.mmdataset(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CMU_MOSI_TimestampedWords', 'CMU_MOSI_Visual_Facet_42', 'CMU_MOSI_OpenSmile_EB10']\n",
      "================================================================================\n",
      "['03bSnISJMiM', '0h-zjBukYpk', '1DmNV9C1hbY', '1iG0909rllw', '2WGyTLYerpo', '2iD-tVS8NPw', '5W7Z1C_fDaE', '6Egk_28TtTM', '6_0THN4chvY', '73jzhE8R1TQ']\n",
      "================================================================================\n",
      "['features', 'intervals']\n",
      "================================================================================\n",
      "(5403, 35) (5403, 2)\n",
      "(645, 1) (645, 2)\n",
      "(25, 1585) (25, 2)\n",
      "Different modalities have different number of time steps!\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset.keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field].keys())[:10])\n",
    "print(\"=\" * 80)\n",
    "\n",
    "some_id = list(dataset[visual_field].keys())[15]\n",
    "print(list(dataset[visual_field][some_id].keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(dataset[visual_field][some_id]['features'].shape, dataset[visual_field][some_id]['intervals'].shape)\n",
    "print(dataset[text_field][some_id]['features'].shape, dataset[text_field][some_id]['intervals'].shape)\n",
    "print(dataset[acoustic_field][some_id]['features'].shape, dataset[acoustic_field][some_id]['intervals'].shape)\n",
    "\n",
    "print(\"Different modalities have different number of time steps!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervals -> \n",
      "[[0.00000e+00 3.33333e-02]\n",
      " [3.33333e-02 6.66667e-02]\n",
      " [6.66667e-02 1.00000e-01]\n",
      " ...\n",
      " [1.80000e+02 1.80033e+02]\n",
      " [1.80033e+02 1.80067e+02]\n",
      " [1.80067e+02 1.80100e+02]]\n",
      "\n",
      "features -> \n",
      "[[-2.25762    0.206646  -1.12043   ... -2.705     -6.46052    4.66611  ]\n",
      " [-2.26915    0.287491  -1.13806   ... -2.69984   -6.46135    4.66685  ]\n",
      " [-2.91823   -0.35709   -0.474069  ... -0.0619697 -4.37588    3.71145  ]\n",
      " ...\n",
      " [-1.80459   -0.191162  -0.915293  ...  4.56445   -0.172315   3.0596   ]\n",
      " [-1.78493   -0.190438  -0.689186  ...  4.20761    0.0100678  3.15838  ]\n",
      " [-1.83387   -0.167352  -0.693682  ...  4.16486    0.0650193  3.12331  ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"intervals -> \\n{dataset[visual_field][some_id]['intervals'][:]}\")\n",
    "print(f\"\\nfeatures -> \\n{dataset[visual_field][some_id]['features'][:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: gensim 4.3.2\n",
      "Uninstalling gensim-4.3.2:\n",
      "  Successfully uninstalled gensim-4.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall gensim -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "total embedded: 2577 common words\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# load the embeddings\n",
    "embed_dim = 300\n",
    "unk = '<UNK>'\n",
    "pad = '<PAD>'\n",
    "wordset = set([unk, pad])\n",
    "\n",
    "for id in train_split:\n",
    "    for w in dataset[text_field][id]['features']:\n",
    "        word = w[0].decode()\n",
    "        if word != 'sp':\n",
    "            wordset.add(word)\n",
    "\n",
    "word2id = defaultdict()\n",
    "id2word = defaultdict()\n",
    "for i, word in enumerate(sorted(list(wordset))):\n",
    "    word2id[word] = i\n",
    "    id2word[i] = word\n",
    "    \n",
    "unk_id = word2id[unk]\n",
    "word2id.default_factory = lambda:unk_id\n",
    "id2word.default_factory = lambda:unk\n",
    "\n",
    "def load_glove():\n",
    "    file = f'./nlpword2vecembeddingspretrained/glove.6B.{embed_dim}d.txt'\n",
    "    embeddings_index = dict()\n",
    "    f = open(file)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = np.mean(all_embs), np.std(all_embs)\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(wordset), embed_dim))\n",
    "    embeddedCount = 0\n",
    "    not_found = []\n",
    "    for word, idx in word2id.items():\n",
    "        embedding_vector = embeddings_index.get(word.lower())\n",
    "        if word == pad:\n",
    "            embedding_vector = np.zeros_like(emb_mean)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "            embeddedCount += 1\n",
    "    print('total embedded:',embeddedCount,'common words')\n",
    "    return embedding_matrix\n",
    "    \n",
    "def load_word2vec():\n",
    "    file = './nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin'\n",
    "    word2vec = KeyedVectors.load_word2vec_format(file, binary=True)\n",
    "    embedding_matrix = np.random.normal(size=(len(wordset), embed_dim))\n",
    "    for word, idx in word2id.items():\n",
    "        if word in word2vec.vocab: \n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        elif word == pad:\n",
    "            embedding_matrix[idx] = np.zeros_like(emb_mean)\n",
    "    return embedding_matrix\n",
    "\n",
    "emb = load_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1m[2024-01-20 06:11:42.108] | Status  | \u001b[0mUnify was called ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:11:42.109] | Warning | \u001b[0mc5xsKMxpXnc entry is not shared among all sequences, removing it ...\n",
      "\u001b[92m\u001b[1m[2024-01-20 06:11:42.109] | Success | \u001b[0mUnify completed ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:11:42.109] | Status  | \u001b[0mPre-alignment based on <CMU_MOSI_TimestampedWords> computational sequence started ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:11:42.235] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_OpenSmile_EB10> ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:11:42.748] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_Visual_Facet_42> ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:11:42.765] | Status  | \u001b[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:21.025] | Success | \u001b[0mAlignment to <CMU_MOSI_TimestampedWords> complete.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:21.025] | Status  | \u001b[0mReplacing dataset content with aligned computational sequences\n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:21.027] | Success | \u001b[0mInitialized empty <CMU_MOSI_TimestampedWords> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:21.027] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_TimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:21.093] | Success | \u001b[0m<CMU_MOSI_TimestampedWords> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:21.093] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWords> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:21.094] | Warning | \u001b[0m<CMU_MOSI_TimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:21.094] | Success | \u001b[0mInitialized empty <CMU_MOSI_Visual_Facet_42> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:21.094] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_Visual_Facet_42> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:21.158] | Success | \u001b[0m<CMU_MOSI_Visual_Facet_42> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:21.159] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_Visual_Facet_42> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:21.159] | Warning | \u001b[0m<CMU_MOSI_Visual_Facet_42> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:21.159] | Success | \u001b[0mInitialized empty <CMU_MOSI_OpenSmile_EB10> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:21.159] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_OpenSmile_EB10> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:21.204] | Success | \u001b[0m<CMU_MOSI_OpenSmile_EB10> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:21.204] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_OpenSmile_EB10> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:21.204] | Warning | \u001b[0m<CMU_MOSI_OpenSmile_EB10> computational sequence does not have all the required metadata ... continuing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# we define a simple averaging function that does not depend on intervals\n",
    "def avg(intervals: np.array, features: np.array) -> np.array:\n",
    "    try:\n",
    "        return np.average(features, axis=0)\n",
    "    except:\n",
    "        return features\n",
    "\n",
    "# first we align to words with averaging, collapse_function receives a list of functions\n",
    "dataset.align(text_field, collapse_functions=[avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:25.119] | Success | \u001b[0mComputational sequence read from file ./cmu_mosi/CMU_MOSI_Opinion_Labels.csd ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.132] | Status  | \u001b[0mChecking the integrity of the <Opinion Segment Labels> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.132] | Status  | \u001b[0mChecking the format of the data in <Opinion Segment Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:25.199] | Success | \u001b[0m<Opinion Segment Labels> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.199] | Status  | \u001b[0mChecking the format of the metadata in <Opinion Segment Labels> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:25.199] | Warning | \u001b[0m<Opinion Segment Labels> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.199] | Status  | \u001b[0mUnify was called ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:25.263] | Warning | \u001b[0mc5xsKMxpXnc entry is not shared among all sequences, removing it ...\n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:25.281] | Success | \u001b[0mUnify completed ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.283] | Status  | \u001b[0mPre-alignment based on <CMU_MOSI_Opinion_Labels> computational sequence started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.391] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_TimestampedWords> ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.516] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_OpenSmile_EB10> ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.607] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_Visual_Facet_42> ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:25.610] | Status  | \u001b[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.535] | Success | \u001b[0mAlignment to <CMU_MOSI_Opinion_Labels> complete.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.535] | Status  | \u001b[0mReplacing dataset content with aligned computational sequences\n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.666] | Success | \u001b[0mInitialized empty <CMU_MOSI_TimestampedWords> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.667] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_TimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.674] | Success | \u001b[0m<CMU_MOSI_TimestampedWords> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.676] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWords> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:27.677] | Warning | \u001b[0m<CMU_MOSI_TimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.679] | Success | \u001b[0mInitialized empty <CMU_MOSI_Visual_Facet_42> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.680] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_Visual_Facet_42> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.688] | Success | \u001b[0m<CMU_MOSI_Visual_Facet_42> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.689] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_Visual_Facet_42> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:27.691] | Warning | \u001b[0m<CMU_MOSI_Visual_Facet_42> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.693] | Success | \u001b[0mInitialized empty <CMU_MOSI_OpenSmile_EB10> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.694] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_OpenSmile_EB10> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.702] | Success | \u001b[0m<CMU_MOSI_OpenSmile_EB10> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.703] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_OpenSmile_EB10> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:27.703] | Warning | \u001b[0m<CMU_MOSI_OpenSmile_EB10> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.704] | Success | \u001b[0mInitialized empty <CMU_MOSI_Opinion_Labels> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.704] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_Opinion_Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 06:12:27.708] | Success | \u001b[0m<CMU_MOSI_Opinion_Labels> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 06:12:27.708] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_Opinion_Labels> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 06:12:27.708] | Warning | \u001b[0m<CMU_MOSI_Opinion_Labels> computational sequence does not have all the required metadata ... continuing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# we add and align to lables to obtain labeled segments\n",
    "# this time we don't apply collapse functions so that the temporal sequences are preserved\n",
    "label_recipe = {label_field: os.path.join(DATA_PATH, label_field + '.csd')}\n",
    "dataset.add_computational_sequences(label_recipe, destination=None)\n",
    "dataset.align(label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03bSnISJMiM[0]', '03bSnISJMiM[1]', '03bSnISJMiM[2]', '03bSnISJMiM[3]', '03bSnISJMiM[4]', '03bSnISJMiM[5]', '03bSnISJMiM[6]', '03bSnISJMiM[7]', '03bSnISJMiM[8]', '03bSnISJMiM[9]']\n",
      "================================================================================\n",
      "(15, 35) (15, 2)\n",
      "(15, 1) (15, 2)\n",
      "(15, 1585) (15, 2)\n",
      "(1, 1) (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset[label_field].keys())[:10])\n",
    "print(\"=\" * 80)\n",
    "\n",
    "some_id = np.random.choice(list(dataset[label_field].keys()))\n",
    "\n",
    "print(dataset[visual_field][some_id]['features'].shape, dataset[visual_field][some_id]['intervals'].shape)\n",
    "print(dataset[text_field][some_id]['features'].shape, dataset[text_field][some_id]['intervals'].shape)\n",
    "print(dataset[acoustic_field][some_id]['features'].shape, dataset[acoustic_field][some_id]['intervals'].shape)\n",
    "print(dataset[label_field][some_id]['features'].shape, dataset[label_field][some_id]['intervals'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padder(instance, length, value=0):\n",
    "    n = instance.shape[0]\n",
    "    q, ex = n // length, n % length\n",
    "    ret = []\n",
    "    for i in range(q):\n",
    "        l = i * length\n",
    "        r = l + length\n",
    "        ret.append((instance[l:r], np.ones(length, dtype=np.int32)))\n",
    "    if ex != 0:\n",
    "        mask = np.zeros(length, dtype=np.int32)\n",
    "        mask[:ex] = 1\n",
    "        cur = np.pad(instance[-ex:], pad_width=((0,length-ex),(0,0)), mode='constant', constant_values=value)\n",
    "        ret.append((cur, mask))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6496/2702216817.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  acoustic = np.nan_to_num((acoustic - acoustic.mean(0, keepdims=True)) / (EPS + np.std(acoustic, axis=0, keepdims=True)))\n",
      "/tmp/ipykernel_6496/2702216817.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  visual = np.nan_to_num((visual - visual.mean(0, keepdims=True)) / (EPS + np.std(visual, axis=0, keepdims=True)))\n",
      "/tmp/ipykernel_6496/2702216817.py:55: RuntimeWarning: divide by zero encountered in divide\n",
      "  acoustic = np.nan_to_num((acoustic - acoustic.mean(0, keepdims=True)) / (EPS + np.std(acoustic, axis=0, keepdims=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 0 datapoints have been dropped.\n"
     ]
    }
   ],
   "source": [
    "EPS = 0\n",
    "# place holders for the final train/dev/test dataset\n",
    "train = []\n",
    "dev = []\n",
    "test = []\n",
    "\n",
    "# define a regular expression to extract the video ID out of the keys\n",
    "pattern = re.compile('(.*)\\[.*\\]')\n",
    "num_drop = 0 # a counter to count how many data points went into some processing issues\n",
    "maxlen = 50\n",
    "\n",
    "my_data = {}\n",
    "for typ in ['train', 'test', 'valid']:\n",
    "    my_data[typ] = {'vision':[], 'audio':[], 'text':[], 'labels':[], 'mask':[]}\n",
    "                       \n",
    "for segment in dataset[label_field].keys():\n",
    "    # get the video ID and the features out of the aligned dataset\n",
    "    vid = re.search(pattern, segment).group(1)\n",
    "    label = dataset[label_field][segment]['features']\n",
    "    _words = dataset[text_field][segment]['features']\n",
    "    _visual = dataset[visual_field][segment]['features']\n",
    "    _acoustic = dataset[acoustic_field][segment]['features']\n",
    "\n",
    "    # if the sequences are not same length after alignment, there must be some problem with some modalities\n",
    "    # we should drop it or inspect the data again\n",
    "    if not _words.shape[0] == _visual.shape[0] == _acoustic.shape[0]:\n",
    "        print(f\"Encountered datapoint {vid} with text shape {_words.shape}, visual shape {_visual.shape}, acoustic shape {_acoustic.shape}\")\n",
    "        num_drop += 1\n",
    "        continue\n",
    "\n",
    "    # remove nan values\n",
    "    label = np.nan_to_num(label)\n",
    "    _visual = np.nan_to_num(_visual)\n",
    "    _acoustic = np.nan_to_num(_acoustic)\n",
    "    \n",
    "    # remove speech pause tokens - this is in general helpful\n",
    "    # we should remove speech pauses and corresponding visual/acoustic features together\n",
    "    # otherwise modalities would no longer be aligned\n",
    "    words = []\n",
    "    visual = []\n",
    "    acoustic = []\n",
    "    for i, word in enumerate(_words):\n",
    "        w = word[0].decode().lower()\n",
    "        if w != 'sp':\n",
    "            words.append(emb[word2id[w]]) # SDK stores strings as bytes, decode into strings here\n",
    "            visual.append(_visual[i])\n",
    "            acoustic.append(_acoustic[i])\n",
    "\n",
    "    words = np.asarray(words)\n",
    "    visual = np.asarray(visual)\n",
    "    acoustic = np.asarray(acoustic)\n",
    "\n",
    "    # z-normalization per instance and remove nan/infs\n",
    "    visual = np.nan_to_num((visual - visual.mean(0, keepdims=True)) / (EPS + np.std(visual, axis=0, keepdims=True)))\n",
    "    acoustic = np.nan_to_num((acoustic - acoustic.mean(0, keepdims=True)) / (EPS + np.std(acoustic, axis=0, keepdims=True)))\n",
    "    \n",
    "    if vid in dev_split:\n",
    "        typ = 'valid'\n",
    "    elif vid in test_split:\n",
    "        typ = 'test'\n",
    "    else:\n",
    "        typ = 'train'\n",
    "\n",
    "    for i in range(words.shape[0]):\n",
    "        my_data[typ]['vision'].append(visual[i])\n",
    "        my_data[typ]['audio'].append(acoustic[i])\n",
    "        my_data[typ]['text'].append(words[i])\n",
    "        my_data[typ]['labels'].append(label[0])\n",
    "        \n",
    "    mask = None\n",
    "    for vision, mask in padder(visual, maxlen, 0):\n",
    "        my_data[typ]['vision'].append(vision)\n",
    "        my_data[typ]['mask'].append(mask)\n",
    "        my_data[typ]['labels'].append(label)\n",
    "    for audio, mask in padder(acoustic, maxlen, 0):\n",
    "        my_data[typ]['audio'].append(audio)\n",
    "    for text, mask in padder(words, maxlen, word2id[pad]):\n",
    "        my_data[typ]['text'].append(text)\n",
    "\n",
    "print(f\"Total number of {num_drop} datapoints have been dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('custom_mosi.pickle', 'wb') as fp:\n",
    "    pickle.dump(my_data, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
