{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 -q install h5py validators tqdm numpy argparse requests colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/CMU-MultiComp-Lab/CMU-MultimodalSDK.git\n",
    "!cp -r CMU-MultimodalSDK/mmsdk ./\n",
    "!rm -rf CMU-MultimodalSDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m[2024-01-20 05:34:11.282] | Error   | \u001b[0m./cmu_mosi/CMU_MOSI_TimestampedWordVectors.csd file already exists ...\n",
      "High-level features have been downloaded previously.\n",
      "\u001b[91m\u001b[1m[2024-01-20 05:34:11.283] | Error   | \u001b[0m./cmu_mosi/CMU_MOSI_TimestampedWords.csd file already exists ...\n",
      "Raw data have been downloaded previously.\n",
      "\u001b[91m\u001b[1m[2024-01-20 05:34:11.283] | Error   | \u001b[0m./cmu_mosi/CMU_MOSI_Opinion_Labels.csd file already exists ...\n",
      "Labels have been downloaded previously.\n"
     ]
    }
   ],
   "source": [
    "import mmsdk\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from mmsdk import mmdatasdk as md\n",
    "from subprocess import check_call, CalledProcessError\n",
    "\n",
    "DATA_PATH = './cmu_mosi/'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "    \n",
    "# download highlevel features, low-level (raw) data and labels for the dataset MOSI\n",
    "# if the files are already present, instead of downloading it you just load it yourself.\n",
    "# here we use CMU_MOSI dataset as example.\n",
    "\n",
    "DATASET = md.cmu_mosi\n",
    "# obtain the train/dev/test splits - these splits are based on video IDs\n",
    "train_split = DATASET.standard_folds.standard_train_fold\n",
    "dev_split = DATASET.standard_folds.standard_valid_fold\n",
    "test_split = DATASET.standard_folds.standard_test_fold\n",
    "\n",
    "try:\n",
    "    md.mmdataset(DATASET.highlevel, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"High-level features have been downloaded previously.\")\n",
    "\n",
    "try:\n",
    "    md.mmdataset(DATASET.raw, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"Raw data have been downloaded previously.\")\n",
    "    \n",
    "try:\n",
    "    md.mmdataset(DATASET.labels, DATA_PATH)\n",
    "except RuntimeError:\n",
    "    print(\"Labels have been downloaded previously.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU_MOSI_TimestampedWordVectors.csd\n",
      "CMU_MOSI_Visual_Facet_42.csd\n",
      "CMU_MOSI_Opinion_Labels.csd\n",
      "CMU_MOSI_TimestampedWords.csd\n",
      "CMU_MOSI_TimestampedPhones.csd\n",
      "CMU_MOSI_openSMILE_IS09.csd\n",
      "CMU_MOSI_OpenSmile_EB10.csd\n",
      "CMU_MOSI_Visual_Facet_41.csd\n"
     ]
    }
   ],
   "source": [
    "data_files = os.listdir(DATA_PATH)\n",
    "print('\\n'.join(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:34:18.302] | Success | \u001b[0mComputational sequence read from file ./cmu_mosi/CMU_MOSI_TimestampedWords.csd ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.315] | Status  | \u001b[0mChecking the integrity of the <words> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.315] | Status  | \u001b[0mChecking the format of the data in <words> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/93 [00:00<?, ? Computational Sequence Entries/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:34:18.393] | Success | \u001b[0m<words> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.393] | Status  | \u001b[0mChecking the format of the metadata in <words> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 05:34:18.393] | Warning | \u001b[0m<words> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 05:34:18.394] | Success | \u001b[0mComputational sequence read from file ./cmu_mosi/CMU_MOSI_Visual_Facet_42.csd ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.406] | Status  | \u001b[0mChecking the integrity of the <FACET_4.2> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.406] | Status  | \u001b[0mChecking the format of the data in <FACET_4.2> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:34:18.483] | Success | \u001b[0m<FACET_4.2> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.483] | Status  | \u001b[0mChecking the format of the metadata in <FACET_4.2> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 05:34:18.483] | Warning | \u001b[0m<FACET_4.2> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 05:34:18.485] | Success | \u001b[0mComputational sequence read from file ./cmu_mosi/CMU_MOSI_OpenSmile_EB10.csd ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.499] | Status  | \u001b[0mChecking the integrity of the <OpenSmile_emobase2010> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.499] | Status  | \u001b[0mChecking the format of the data in <OpenSmile_emobase2010> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:34:18.585] | Success | \u001b[0m<OpenSmile_emobase2010> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:34:18.585] | Status  | \u001b[0mChecking the format of the metadata in <OpenSmile_emobase2010> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 05:34:18.585] | Warning | \u001b[0m<OpenSmile_emobase2010> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 05:34:18.585] | Success | \u001b[0mDataset initialized successfully ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# define your different modalities - refer to the filenames of the CSD files\n",
    "visual_field = 'CMU_MOSI_Visual_Facet_42'\n",
    "acoustic_field = 'CMU_MOSI_OpenSmile_EB10'\n",
    "text_field = 'CMU_MOSI_TimestampedWords'\n",
    "label_field = 'CMU_MOSI_Opinion_Labels'\n",
    "\n",
    "features = [\n",
    "    text_field, \n",
    "    visual_field, \n",
    "    acoustic_field,\n",
    "]\n",
    "\n",
    "recipe = {feat: os.path.join(DATA_PATH, feat) + '.csd' for feat in features}\n",
    "dataset = md.mmdataset(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CMU_MOSI_TimestampedWords', 'CMU_MOSI_Visual_Facet_42', 'CMU_MOSI_OpenSmile_EB10']\n",
      "================================================================================\n",
      "['03bSnISJMiM', '0h-zjBukYpk', '1DmNV9C1hbY', '1iG0909rllw', '2WGyTLYerpo', '2iD-tVS8NPw', '5W7Z1C_fDaE', '6Egk_28TtTM', '6_0THN4chvY', '73jzhE8R1TQ']\n",
      "================================================================================\n",
      "['features', 'intervals']\n",
      "================================================================================\n",
      "(5403, 35) (5403, 2)\n",
      "(645, 1) (645, 2)\n",
      "(25, 1585) (25, 2)\n",
      "Different modalities have different number of time steps!\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset.keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field].keys())[:10])\n",
    "print(\"=\" * 80)\n",
    "\n",
    "some_id = list(dataset[visual_field].keys())[15]\n",
    "print(list(dataset[visual_field][some_id].keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(dataset[visual_field][some_id]['features'].shape, dataset[visual_field][some_id]['intervals'].shape)\n",
    "print(dataset[text_field][some_id]['features'].shape, dataset[text_field][some_id]['intervals'].shape)\n",
    "print(dataset[acoustic_field][some_id]['features'].shape, dataset[acoustic_field][some_id]['intervals'].shape)\n",
    "\n",
    "print(\"Different modalities have different number of time steps!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervals -> \n",
      "[[0.00000e+00 3.33333e-02]\n",
      " [3.33333e-02 6.66667e-02]\n",
      " [6.66667e-02 1.00000e-01]\n",
      " ...\n",
      " [1.80000e+02 1.80033e+02]\n",
      " [1.80033e+02 1.80067e+02]\n",
      " [1.80067e+02 1.80100e+02]]\n",
      "\n",
      "features -> \n",
      "[[-2.25762    0.206646  -1.12043   ... -2.705     -6.46052    4.66611  ]\n",
      " [-2.26915    0.287491  -1.13806   ... -2.69984   -6.46135    4.66685  ]\n",
      " [-2.91823   -0.35709   -0.474069  ... -0.0619697 -4.37588    3.71145  ]\n",
      " ...\n",
      " [-1.80459   -0.191162  -0.915293  ...  4.56445   -0.172315   3.0596   ]\n",
      " [-1.78493   -0.190438  -0.689186  ...  4.20761    0.0100678  3.15838  ]\n",
      " [-1.83387   -0.167352  -0.693682  ...  4.16486    0.0650193  3.12331  ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"intervals -> \\n{dataset[visual_field][some_id]['intervals'][:]}\")\n",
    "print(f\"\\nfeatures -> \\n{dataset[visual_field][some_id]['features'][:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/nlpword2vecembeddingspretrained/glove.6B.300d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m             embedding_matrix[idx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(emb_mean)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding_matrix\n\u001b[0;32m---> 62\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mload_glove\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mload_glove\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/nlpword2vecembeddingspretrained/glove.6B.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124md.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m embeddings_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 27\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m     29\u001b[0m     values \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[0;32m~/Projects/MSA/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/nlpword2vecembeddingspretrained/glove.6B.300d.txt'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# load the embeddings\n",
    "embed_dim = 300\n",
    "unk = '<UNK>'\n",
    "pad = '<PAD>'\n",
    "wordset = set([unk, pad])\n",
    "\n",
    "for id in train_split:\n",
    "    for w in dataset[text_field][id]['features']:\n",
    "        word = w[0].decode()\n",
    "        if word != 'sp':\n",
    "            wordset.add(word)\n",
    "\n",
    "word2id = defaultdict()\n",
    "id2word = defaultdict()\n",
    "for i, word in enumerate(sorted(list(wordset))):\n",
    "    word2id[word] = i\n",
    "    id2word[i] = word\n",
    "    \n",
    "unk_id = word2id[unk]\n",
    "word2id.default_factory = lambda:unk_id\n",
    "id2word.default_factory = lambda:unk\n",
    "\n",
    "def load_glove():\n",
    "    file = f'../input/nlpword2vecembeddingspretrained/glove.6B.{embed_dim}d.txt'\n",
    "    embeddings_index = dict()\n",
    "    f = open(file)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = np.mean(all_embs), np.std(all_embs)\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(wordset), embed_dim))\n",
    "    embeddedCount = 0\n",
    "    not_found = []\n",
    "    for word, idx in word2id.items():\n",
    "        embedding_vector = embeddings_index.get(word.lower())\n",
    "        if word == pad:\n",
    "            embedding_vector = np.zeros_like(emb_mean)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "            embeddedCount += 1\n",
    "    print('total embedded:',embeddedCount,'common words')\n",
    "    return embedding_matrix\n",
    "    \n",
    "def load_word2vec():\n",
    "    file = '../input/nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin'\n",
    "    word2vec = KeyedVectors.load_word2vec_format(file, binary=True)\n",
    "    embedding_matrix = np.random.normal(size=(len(wordset), embed_dim))\n",
    "    for word, idx in word2id.items():\n",
    "        if word in word2vec.vocab: \n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        elif word == pad:\n",
    "            embedding_matrix[idx] = np.zeros_like(emb_mean)\n",
    "    return embedding_matrix\n",
    "\n",
    "emb = load_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1m[2024-01-20 05:35:18.677] | Status  | \u001b[0mUnify was called ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 05:35:18.677] | Warning | \u001b[0mc5xsKMxpXnc entry is not shared among all sequences, removing it ...\n",
      "\u001b[92m\u001b[1m[2024-01-20 05:35:18.679] | Success | \u001b[0mUnify completed ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:35:18.679] | Status  | \u001b[0mPre-alignment based on <CMU_MOSI_TimestampedWords> computational sequence started ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:35:19.065] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_OpenSmile_EB10> ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:35:20.602] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_Visual_Facet_42> ...\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:35:20.616] | Status  | \u001b[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:37:15.489] | Success | \u001b[0mAlignment to <CMU_MOSI_TimestampedWords> complete.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:37:15.489] | Status  | \u001b[0mReplacing dataset content with aligned computational sequences\n",
      "\u001b[92m\u001b[1m[2024-01-20 05:37:15.492] | Success | \u001b[0mInitialized empty <CMU_MOSI_TimestampedWords> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:37:15.492] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_TimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:37:15.591] | Success | \u001b[0m<CMU_MOSI_TimestampedWords> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:37:15.591] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWords> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 05:37:15.591] | Warning | \u001b[0m<CMU_MOSI_TimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 05:37:15.591] | Success | \u001b[0mInitialized empty <CMU_MOSI_Visual_Facet_42> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:37:15.591] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_Visual_Facet_42> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:37:15.693] | Success | \u001b[0m<CMU_MOSI_Visual_Facet_42> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:37:15.693] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_Visual_Facet_42> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 05:37:15.693] | Warning | \u001b[0m<CMU_MOSI_Visual_Facet_42> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-01-20 05:37:15.693] | Success | \u001b[0mInitialized empty <CMU_MOSI_OpenSmile_EB10> computational sequence.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:37:15.693] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_OpenSmile_EB10> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-01-20 05:37:15.766] | Success | \u001b[0m<CMU_MOSI_OpenSmile_EB10> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-01-20 05:37:15.766] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_OpenSmile_EB10> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-01-20 05:37:15.766] | Warning | \u001b[0m<CMU_MOSI_OpenSmile_EB10> computational sequence does not have all the required metadata ... continuing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# we define a simple averaging function that does not depend on intervals\n",
    "def avg(intervals: np.array, features: np.array) -> np.array:\n",
    "    try:\n",
    "        return np.average(features, axis=0)\n",
    "    except:\n",
    "        return features\n",
    "\n",
    "# first we align to words with averaging, collapse_function receives a list of functions\n",
    "dataset.align(text_field, collapse_functions=[avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add and align to lables to obtain labeled segments\n",
    "# this time we don't apply collapse functions so that the temporal sequences are preserved\n",
    "label_recipe = {label_field: os.path.join(DATA_PATH, label_field + '.csd')}\n",
    "dataset.add_computational_sequences(label_recipe, destination=None)\n",
    "dataset.align(label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(dataset[label_field].keys())[:10])\n",
    "print(\"=\" * 80)\n",
    "\n",
    "some_id = np.random.choice(list(dataset[label_field].keys()))\n",
    "\n",
    "print(dataset[visual_field][some_id]['features'].shape, dataset[visual_field][some_id]['intervals'].shape)\n",
    "print(dataset[text_field][some_id]['features'].shape, dataset[text_field][some_id]['intervals'].shape)\n",
    "print(dataset[acoustic_field][some_id]['features'].shape, dataset[acoustic_field][some_id]['intervals'].shape)\n",
    "print(dataset[label_field][some_id]['features'].shape, dataset[label_field][some_id]['intervals'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padder(instance, length, value=0):\n",
    "    n = instance.shape[0]\n",
    "    q, ex = n // length, n % length\n",
    "    ret = []\n",
    "    for i in range(q):\n",
    "        l = i * length\n",
    "        r = l + length\n",
    "        ret.append((instance[l:r], np.ones(length, dtype=np.int32)))\n",
    "    if ex != 0:\n",
    "        mask = np.zeros(length, dtype=np.int32)\n",
    "        mask[:ex] = 1\n",
    "        cur = np.pad(instance[-ex:], pad_width=((0,length-ex),(0,0)), mode='constant', constant_values=value)\n",
    "        ret.append((cur, mask))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 0\n",
    "# place holders for the final train/dev/test dataset\n",
    "train = []\n",
    "dev = []\n",
    "test = []\n",
    "\n",
    "# define a regular expression to extract the video ID out of the keys\n",
    "pattern = re.compile('(.*)\\[.*\\]')\n",
    "num_drop = 0 # a counter to count how many data points went into some processing issues\n",
    "maxlen = 50\n",
    "\n",
    "my_data = {}\n",
    "for typ in ['train', 'test', 'valid']:\n",
    "    my_data[typ] = {'vision':[], 'audio':[], 'text':[], 'labels':[], 'mask':[]}\n",
    "                       \n",
    "for segment in dataset[label_field].keys():\n",
    "    # get the video ID and the features out of the aligned dataset\n",
    "    vid = re.search(pattern, segment).group(1)\n",
    "    label = dataset[label_field][segment]['features']\n",
    "    _words = dataset[text_field][segment]['features']\n",
    "    _visual = dataset[visual_field][segment]['features']\n",
    "    _acoustic = dataset[acoustic_field][segment]['features']\n",
    "\n",
    "    # if the sequences are not same length after alignment, there must be some problem with some modalities\n",
    "    # we should drop it or inspect the data again\n",
    "    if not _words.shape[0] == _visual.shape[0] == _acoustic.shape[0]:\n",
    "        print(f\"Encountered datapoint {vid} with text shape {_words.shape}, visual shape {_visual.shape}, acoustic shape {_acoustic.shape}\")\n",
    "        num_drop += 1\n",
    "        continue\n",
    "\n",
    "    # remove nan values\n",
    "    label = np.nan_to_num(label)\n",
    "    _visual = np.nan_to_num(_visual)\n",
    "    _acoustic = np.nan_to_num(_acoustic)\n",
    "    \n",
    "    # remove speech pause tokens - this is in general helpful\n",
    "    # we should remove speech pauses and corresponding visual/acoustic features together\n",
    "    # otherwise modalities would no longer be aligned\n",
    "    words = []\n",
    "    visual = []\n",
    "    acoustic = []\n",
    "    for i, word in enumerate(_words):\n",
    "        w = word[0].decode().lower()\n",
    "        if w != 'sp':\n",
    "            words.append(emb[word2id[w]]) # SDK stores strings as bytes, decode into strings here\n",
    "            visual.append(_visual[i])\n",
    "            acoustic.append(_acoustic[i])\n",
    "\n",
    "    words = np.asarray(words)\n",
    "    visual = np.asarray(visual)\n",
    "    acoustic = np.asarray(acoustic)\n",
    "\n",
    "    # z-normalization per instance and remove nan/infs\n",
    "    visual = np.nan_to_num((visual - visual.mean(0, keepdims=True)) / (EPS + np.std(visual, axis=0, keepdims=True)))\n",
    "    acoustic = np.nan_to_num((acoustic - acoustic.mean(0, keepdims=True)) / (EPS + np.std(acoustic, axis=0, keepdims=True)))\n",
    "\n",
    "    if vid in dev_split:\n",
    "        typ = 'valid'\n",
    "    elif vid in test_split:\n",
    "        typ = 'test'\n",
    "    else:\n",
    "        typ = 'train'\n",
    "\n",
    "    for i in range(words.shape[0]):\n",
    "        my_data[typ]['vision'].append(visual[i])\n",
    "        my_data[typ]['audio'].append(acoustic[i])\n",
    "        my_data[typ]['text'].append(words[i])\n",
    "        my_data[typ]['labels'].append(label[0])\n",
    "        \n",
    "    mask = None\n",
    "    for vision, mask in padder(visual, maxlen, 0):\n",
    "        my_data[typ]['vision'].append(vision)\n",
    "        my_data[typ]['mask'].append(mask)\n",
    "        my_data[typ]['labels'].append(label)\n",
    "    for audio, mask in padder(acoustic, maxlen, 0):\n",
    "        my_data[typ]['audio'].append(audio)\n",
    "    for text, mask in padder(words, maxlen, word2id[pad]):\n",
    "        my_data[typ]['text'].append(text)\n",
    "\n",
    "print(f\"Total number of {num_drop} datapoints have been dropped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
